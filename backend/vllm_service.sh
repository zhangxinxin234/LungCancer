CUDA_VISIBLE_DEVICES=0 python -m vllm.entrypoints.openai.api_server \
    --port 7853 \
    --host 127.0.0.1 \
    --model "/root/model/plm/Qwen2.5-14B-Instruct" \
    --dtype bfloat16 \
    --max-model-len 8192 \
    --served-model-name qwen \
    --tensor-parallel-size 1 \
    --gpu-memory-utilization 0.8 \
    --enable-lora \
    --lora-modules Qwen2.5-14B_cotrc_no_r8a16="/root/model/saves/lung_cancer_lora/2025_04_01_Qwen2.5-14B_cotrc_no_r8a16"